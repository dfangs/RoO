{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read RoO data\n",
    "roo_texts = {}\n",
    "roo_folder = 'RoO Non-table/roo_clean_2'\n",
    "\n",
    "# roo_clean_2 -> UTF-8 ('cause Ms. Word?), roo_clean -> ANSI\n",
    "for filename in os.listdir(roo_folder):\n",
    "    with open(roo_folder + '/' + filename, mode='r', encoding='utf-8') as f:\n",
    "        # Replace en dash with hyphen\n",
    "        roo_texts[filename[:-4]] = f.read().replace('â€“', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRN_JPN 21\n",
      "CHL_JPN 21\n",
      "IDN_JPN 21\n",
      "IND_JPN 17\n",
      "JPN_MEX 21\n",
      "JPN_MYS 21\n",
      "JPN_PER 21\n",
      "JPN_PHL 21\n",
      "JPN_THA 21\n"
     ]
    }
   ],
   "source": [
    "# Check how many sections within the RoO\n",
    "# Apparently India is missing some sections: X, XIV, XIX, XXI\n",
    "pattern_count = re.compile('Section [IVX]{1,5}')\n",
    "for fta, rule in roo_texts.items():\n",
    "    print(fta, len(pattern_count.findall(rule)))\n",
    "\n",
    "# Clean some misconverted HS code\n",
    "# Update apparently there are no misconverted hs code with new file!\n",
    "def addZero(matchobj):\n",
    "    \"\"\"Example: Instead of 21.6, which is a wrong HS code, return 21.06\"\"\"\n",
    "    hs_code = matchobj[0]\n",
    "    return hs_code[:-1] + '0' + hs_code[-1]\n",
    "\n",
    "#pattern_zero = re.compile(r'\\b\\d{1,2}\\.\\d\\b')\n",
    "#for fta, rule in roo_texts.items():\n",
    "#    roo_texts[fta] = pattern_zero.sub(addZero, rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv files of different versions of HS code mapping\n",
    "HS_maps = {\n",
    "    2002: pd.read_csv('HS2.csv'),\n",
    "    2007: pd.read_csv('HS3.csv'),\n",
    "    2012: pd.read_csv('HS4.csv'),\n",
    "    2017: pd.read_csv('HS5.csv')\n",
    "}\n",
    "\n",
    "# Read the HS code version used in each agreement\n",
    "HS_map_used = {}\n",
    "for row in pd.read_csv('HS_ver.csv').itertuples(index=None, name=None):\n",
    "    HS_map_used[row[0]] = HS_maps[row[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['390610', '390690', '390710', '390720', '390730', '390740', '390750', '390760', '390791', '390799']\n"
     ]
    }
   ],
   "source": [
    "# FUNCTION FOR EXTRACTING HS CODES\n",
    "def get_hs_codes(hs_code1, hs_code2, HS_map):\n",
    "    \"\"\"Given a range of HS codes, return list of all HS codes within.\"\"\"\n",
    "    # Clean HS codes\n",
    "    hs_code1 = hs_code1.replace('.', '')\n",
    "    hs_code2 = hs_code2.replace('.', '')\n",
    "    \n",
    "    if not hs_code2:\n",
    "        result = HS_map.loc[(HS_map['ProductCode'].str.startswith(hs_code1)) & (HS_map['Tier'] == 3)]\n",
    "        return list(result['ProductCode'])\n",
    "        \n",
    "    try:\n",
    "        # Is there a way to index by value? HS_map['ProductCode'].indval(hs_code) ?\n",
    "        index_1 = HS_map.loc[HS_map['ProductCode'] == hs_code1].index[0]\n",
    "        index_2 = HS_map.loc[HS_map['ProductCode'] == hs_code2].index[0]\n",
    "\n",
    "        range_1 = HS_map.loc[HS_map['Tier'] == 3].loc[index_1:index_2]\n",
    "        range_2 = HS_map.loc[(HS_map['ProductCode'].str.startswith(hs_code2)) & (HS_map['ProductCode'] != hs_code2)\n",
    "                             & (HS_map['Tier'] == 3)]\n",
    "\n",
    "        result = pd.concat([range_1, range_2], ignore_index=True)\n",
    "        return list(result['ProductCode'])\n",
    "\n",
    "    except:\n",
    "        print(hs_code1, hs_code2)\n",
    "\n",
    "print(get_hs_codes('39.06', '39.07', HS_maps[2002]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A DICTIONARY FOR FASTER ACCESS TO ALL HS CODES\n",
    "def expand_map(HS_map):\n",
    "    \"\"\"Given part of HS code (chapter, heading, or subheading), return list\n",
    "    containing all 6-digit HS code within it.\n",
    "    \"\"\"\n",
    "    expanded_map = {}\n",
    "    # Expand chapters\n",
    "    chapters = HS_map.loc[HS_map['Tier'] == 1]\n",
    "    for row in chapters.itertuples(index=False, name=None):\n",
    "        result = HS_map.loc[(HS_map['ProductCode'].str.startswith(row[1])) & (HS_map['Tier'] == 3)]\n",
    "        expanded_map[row[1]] = list(result['ProductCode'])\n",
    "    \n",
    "    # Expand headings\n",
    "    headings = HS_map.loc[HS_map['Tier'] == 2]\n",
    "    for row in headings.itertuples(index=False, name=None):\n",
    "        result = HS_map.loc[(HS_map['ProductCode'].str.startswith(row[1])) & (HS_map['Tier'] == 3)]\n",
    "        expanded_map[row[1]] = list(result['ProductCode'])\n",
    "    \n",
    "    # Expand subheadings\n",
    "    subheadings = HS_map.loc[HS_map['Tier'] == 3]\n",
    "    for row in subheadings.itertuples(index=False, name=None):\n",
    "        expanded_map[row[1]] = row[1]\n",
    "    \n",
    "    return expanded_map\n",
    "\n",
    "HS_exp_maps = {\n",
    "    2002: expand_map(HS_maps[2002]),\n",
    "    2007: expand_map(HS_maps[2007]),\n",
    "    2012: expand_map(HS_maps[2012]),\n",
    "    2017: expand_map(HS_maps[2017])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRN_JPN 5222\n",
      "CHL_JPN 5212\n",
      "IDN_JPN 5210\n",
      "IND_JPN 2474\n",
      "JPN_MEX 5224\n",
      "JPN_MYS 5158\n",
      "JPN_PER 5046\n",
      "JPN_PHL 5222\n",
      "JPN_THA 5214\n",
      "HS 2002 : 5224\n",
      "HS 2007 : 5053\n",
      "HS 2012 : 5205\n",
      "HS 2017 : 6276\n"
     ]
    }
   ],
   "source": [
    "# Useful groups for regular expressions\n",
    "HS_CODE = r'(\\d+\\.\\d+)'\n",
    "HS_CODE_NC = r'(?:\\d+\\.\\d+)'\n",
    "HS_RANGE = r'({0}(?:\\-{0})?)'.format(HS_CODE)\n",
    "HS_RANGE_NC = r'{0}(?:\\-{0})?'.format(HS_CODE_NC)\n",
    "\n",
    "def parse_roo(roo_text):\n",
    "    \"\"\"Given complete text of specific rules of origin, return a dictionary representing\n",
    "    the complete structure of RoO (from sections to chapters)\n",
    "    \n",
    "    Argument:\n",
    "        roo_text\n",
    "    Return:\n",
    "        \n",
    "    \"\"\"\n",
    "    def clean_ws(match):\n",
    "        \"\"\"Reduce number of whitespaces into a single space.\"\"\"\n",
    "        return ' '\n",
    "\n",
    "    # Capture sections\n",
    "    pattern_section = re.compile(r'(Section [IVX]{1,5})\\s+(.+?)(?=Section [IVX]{1,5}\\s+[A-Z]|\\Z)', flags=re.DOTALL)\n",
    "    result = pattern_section.findall(roo_text)\n",
    "    roo = {match[0]: match[1] for match in result}\n",
    "\n",
    "    # Capture chapters in every section\n",
    "    pattern_chapter = re.compile(r'(Chapter \\d{1,2})\\s+(.+?)(?=Chapter \\d{1,2}\\s+[A-Z]|\\Z)', flags=re.DOTALL)\n",
    "    for section, content in roo.items():\n",
    "        result = pattern_chapter.findall(content)\n",
    "        roo[section] = {match[0]: match[1] for match in result}\n",
    "\n",
    "    # Capture rules in every chapter\n",
    "    pattern_rule = re.compile(HS_RANGE + r'\\s+([A-Z].+?\\.)(?=\\s+' + HS_RANGE_NC + r'|\\s*\\Z)', flags=re.DOTALL)\n",
    "    pattern_whitespace = re.compile(r'\\s+')    \n",
    "    for section in roo:\n",
    "        for chapter, rules in roo[section].items():\n",
    "            result = pattern_rule.findall(rules)\n",
    "            roo[section][chapter] = {match[0]: pattern_whitespace.sub(clean_ws, match[3]) for match in result}\n",
    "    return roo\n",
    "\n",
    "def get_roo_rules(roo, HS_map=None, complete=False):\n",
    "    \"\"\"Create a dictionary which only stores the rules without additional stuctures\"\"\"\n",
    "    roo_rules = {}\n",
    "    pattern_range = re.compile(HS_RANGE)\n",
    "    for section in roo:\n",
    "        for chapter in roo[section]:\n",
    "            for hs_code_range, rule in roo[section][chapter].items():\n",
    "                if complete:\n",
    "                    #print(hs_code_range)\n",
    "                    result = pattern_range.findall(hs_code_range)\n",
    "                    hs_codes = get_hs_codes(result[0][1], result[0][2], HS_map)\n",
    "                    for hs_code in hs_codes:\n",
    "                        roo_rules[hs_code] = rule\n",
    "                else:\n",
    "                    roo_rules[hs_code_range] = rule\n",
    "    return roo_rules\n",
    "\n",
    "\n",
    "roo_rules = {fta: {} for fta in roo_texts}\n",
    "for fta, roo_text in roo_texts.items():\n",
    "    roo_rules[fta] = get_roo_rules(parse_roo(roo_text), HS_map_used[fta], complete=True)\n",
    "    print(fta, len(roo_rules[fta]))\n",
    "    \n",
    "# NOTE!!!\n",
    "# JPN_PHL, 15.16 - 15.19 -> TYPO??? CHANGE TO 15.18\n",
    "\n",
    "for ver, HS_map in HS_maps.items():\n",
    "    print('HS', ver, ':', HS_map.loc[HS_map['Tier'] == 3]['ProductCode'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one = set(get_roo_rules(parse_roo(roo_texts['IND_JPN'], get_hs_map('IND_JPN'), complete=True)))\n",
    "#two = set(get_roo_rules(parse_roo(roo_texts['JPN_PER'], get_hs_map('JPN_PER'), complete=True)))\n",
    "#sorted(list(two-one))\n",
    "#roo_texts['IND_JPN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRN_JPN 4\n",
      "CHL_JPN 4\n",
      "IDN_JPN 7\n",
      "IND_JPN 7\n",
      "JPN_MEX 57\n",
      "JPN_MYS 9\n",
      "JPN_PER 4\n",
      "JPN_PHL 12\n",
      "JPN_THA 7\n"
     ]
    }
   ],
   "source": [
    "# NEXT PROJECT: ANALYZE GRAMMAR\n",
    "patterns = {\n",
    "    'CC': re.compile(r'A change to (?:heading|subheading) {0}(?: through {0})? from any other chapter.'.format(HS_CODE_NC)),\n",
    "    'CTH': re.compile(r'A change to (?:heading|subheading) {0}(?: through {0})? from any other heading.'.format(HS_CODE_NC)),\n",
    "    'CTSH': re.compile(r'A change to (?:heading|subheading) {0}(?: through {0})? from any other subheading.'.format(HS_CODE_NC)),\n",
    "    'CTH_RVC': re.compile(r'A change to (?:heading|subheading) {0}(?: through {0})? from(?: subheading {0} or)? any other heading, provided there is a regional value content of not less than \\d\\d? percent.'.format(HS_CODE_NC)),\n",
    "    'WO': re.compile(r'(?:Manufacture in which all the materials used are wholly obtained.|Goods of (?:heading|subheading) {0}(?: through {0})? are wholly obtained or produced entirely in a Party\\,? as defined in Article \\d\\d?.)'.format(HS_CODE_NC)),\n",
    "    'RVC': re.compile(r'(?:No required change in tariff classification to (?:heading|subheading) {0}(?: through {0})?, provided(?: that)? there is a (?:qualifying|regional) value content of not less than \\d\\d? per\\s?cent.|A qualifying value content of not less than \\d\\d? percent.)'.format(HS_CODE_NC)),\n",
    "    'WO_scrap': re.compile(r'No required change in tariff classification to (?:heading|subheading) {0}(?: through {0})?, provided(?: that)? the waste(?: and scrap are)?(?: is)? wholly obtained or produced entirely in (?:a Party|the Area of one or both Parties|the territory of a Country) as defined in Article \\d\\d?(?: of Chapter \\d\\d?)?.'.format(HS_CODE_NC)),\n",
    "    'CTH_ECT': re.compile(r'A change to (?:heading|subheading) {0}(?: through {0})? from any heading outside that group.'.format(HS_CODE)),\n",
    "    'CTSH_ECT': re.compile(r'A change to subheading {0}(?: through {0})? from any subheading outside that group.'.format(HS_CODE)),\n",
    "    'Manufacture_1': re.compile(r'Manufacture from (?:yarns|fibres|fabrics|chemical materials or textile pulps), provided that necessary process stipulated in the Appendix is undertaken.'),\n",
    "    'Manufacture_2': re.compile(r'Manufacture from (?:yarns|fibres|fabrics|chemical materials or textile pulps).'),\n",
    "\n",
    "    'pattern_1': re.compile(r'A change to subheading {0} from any classification to subheading {0}, provided that there is a qualifying value content of not less than \\d\\d? percent.'.format(HS_CODE_NC)),\n",
    "    'pattern_2': re.compile(r'All the animals of Chapter 1 shall be wholly obtained.')\n",
    "}\n",
    "\n",
    "patterns_small = {\n",
    "    'CC': re.compile(r'A change to (?:heading|subheading) {0}(?: through {0})? from any other chapter.'.format(HS_CODE_NC)),\n",
    "    'CTH': re.compile(r'A change to (?:heading|subheading) {0}(?: through {0})? from any other heading.'.format(HS_CODE_NC)),\n",
    "    'CTSH': re.compile(r'A change to (?:heading|subheading) {0}(?: through {0})? from any other subheading.'.format(HS_CODE_NC)),\n",
    "    'CTH_RVC': re.compile(r'A change to (?:heading|subheading) {0}(?: through {0})? from(?: subheading {0} or)? any other heading, provided there is a regional value content of not less than \\d\\d? percent.'.format(HS_CODE_NC)),\n",
    "    'CTH_ECT': re.compile(r'A change to (?:heading|subheading) {0}(?: through {0})? from any heading outside that group.'.format(HS_CODE_NC)),\n",
    "    'CTSH_ECT': re.compile(r'A change to subheading {0}(?: through {0})? from any subheading outside that group.'.format(HS_CODE_NC)),\n",
    "}\n",
    "\n",
    "for fta in roo_rules:\n",
    "    begin = Counter()\n",
    "    for hsc, rule in roo_rules[fta].items():\n",
    "        res = []\n",
    "        for pattern in patterns.values():\n",
    "            res.append(pattern.search(rule))\n",
    "        if any(res):\n",
    "            #print(pattern1.search(rule))\n",
    "            continue\n",
    "        begin[rule[:20]] += 1\n",
    "        if fta == 'JPN_THA':\n",
    "            pass\n",
    "            #print(rule)\n",
    "    print(fta, sum(begin.values()))\n",
    "    #print(begin, end='\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming complete=True\n",
    "final_roo = {fta: {} for fta in roo_rules}\n",
    "for fta in roo_rules:\n",
    "    hs_map_ex = get_hs_map_ex(fta)\n",
    "    \n",
    "    for hs_code, rule in roo_rules[fta].items():\n",
    "        for roo_type, pattern in patterns_small.items():\n",
    "            match = pattern.search(rule)\n",
    "            if match:\n",
    "                if roo_type == 'CC':\n",
    "                    final_roo[fta][hs_code] = hs_map_ex[hs_code[:2]]\n",
    "                if roo_type == 'CTH' or roo_type == 'CTH_RVC':\n",
    "                    final_roo[fta][hs_code] = hs_map_ex[hs_code[:4]]\n",
    "                if roo_type == 'CTSH':                    \n",
    "                    final_roo[fta][hs_code] = hs_map_ex[hs_code[:6]]\n",
    "                if roo_type == 'CTH_ECT':\n",
    "                    \n",
    "                if roo_type == 'CTSH_ECT':\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4835"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_roo['JPN_MYS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRN_JPN\n",
      "Counter({'subheading': 3240,\n",
      "         'chapter': 1392,\n",
      "         'heading': 226,\n",
      "         'no rule': 197,\n",
      "         'else': 97,\n",
      "         'wholly': 66,\n",
      "         'value': 4})\n",
      "CHL_JPN\n",
      "Counter({'heading': 2265,\n",
      "         'chapter': 1796,\n",
      "         'subheading': 727,\n",
      "         'else': 346,\n",
      "         'wholly': 35,\n",
      "         'no rule': 25,\n",
      "         'value': 18})\n",
      "IDN_JPN\n",
      "Counter({'subheading': 2660,\n",
      "         'chapter': 1562,\n",
      "         'heading': 746,\n",
      "         'no rule': 163,\n",
      "         'else': 70,\n",
      "         'wholly': 9})\n",
      "IND_JPN\n",
      "Counter()\n",
      "JPN_MEX\n",
      "Counter({'chapter': 2422,\n",
      "         'heading': 1672,\n",
      "         'subheading': 517,\n",
      "         'else': 507,\n",
      "         'value': 49})\n",
      "JPN_MYS\n",
      "Counter({'subheading': 2662,\n",
      "         'chapter': 1351,\n",
      "         'heading': 828,\n",
      "         'no rule': 200,\n",
      "         'else': 79,\n",
      "         'value': 29})\n",
      "JPN_PER\n",
      "Counter()\n",
      "JPN_PHL\n",
      "Counter({'chapter': 1917,\n",
      "         'heading': 1851,\n",
      "         'subheading': 1081,\n",
      "         'no rule': 200,\n",
      "         'wholly': 79,\n",
      "         'else': 61,\n",
      "         'value': 33})\n",
      "JPN_THA\n",
      "Counter({'heading': 2151,\n",
      "         'chapter': 1671,\n",
      "         'subheading': 996,\n",
      "         'else': 304,\n",
      "         'wholly': 65,\n",
      "         'value': 27})\n"
     ]
    }
   ],
   "source": [
    "# TRY NEW ONE\n",
    "# Count types of RoO in every FTA\n",
    "roo_types_count = {}\n",
    "pattern_chapter = re.compile(r'A change to.+?from any other chapter', flags=re.DOTALL)\n",
    "pattern_heading = re.compile(r'A change to.+?from any other heading', flags=re.DOTALL)\n",
    "pattern_subheading = re.compile(r'A change to.+?from any other subheading', flags=re.DOTALL)\n",
    "\n",
    "for fta in roo_rules:\n",
    "    freq = Counter()\n",
    "    for hs_code, rule in roo_rules[fta].items():\n",
    "        # Chapter level\n",
    "        if pattern_chapter.search(rule):\n",
    "            freq['chapter'] += 1\n",
    "        \n",
    "        # Heading level\n",
    "        elif pattern_heading.search(rule):\n",
    "            freq['heading'] += 1\n",
    "        \n",
    "        # Subheading level\n",
    "        # Note: There are a few specific rules related to chemicals (e.g. alkali metal; \"or any other subheading\")\n",
    "        elif pattern_subheading.search(rule):\n",
    "            freq['subheading'] += 1\n",
    "            \n",
    "        # \"Wholly obtained\"\n",
    "        elif 'are wholly' in rule:\n",
    "            freq['wholly'] += 1\n",
    "\n",
    "        # Manufacture criteria?\n",
    "        elif 'Manufacture from' in rule:\n",
    "            freq['manufacture'] += 1\n",
    "        \n",
    "        # Value added?\n",
    "        elif 'A qualifying value content of not less than' in rule or 'value content' in rule:\n",
    "            freq['value'] += 1\n",
    "            \n",
    "        # No rules imposed, unless...\n",
    "        elif 'No required change in tariff' in rule or 'No change in tariff' in rule:\n",
    "            freq['no rule'] += 1\n",
    "        \n",
    "        # Other notes\n",
    "        else:\n",
    "            freq['else'] += 1\n",
    "            \n",
    "    roo_types_count[fta] = freq\n",
    "    print(fta)\n",
    "    pprint.pprint(freq, width=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTA\t\tChapter\t\tHeading\t\tSubheading\tOther\t\tTotal\n",
      "BRN_JPN\t\t26.69%\t\t9.92%\t\t62.05%\t\t1.34%\t\t5222\n",
      "CHL_JPN\t\t34.46%\t\t49.46%\t\t14.58%\t\t1.50%\t\t5212\n",
      "IDN_JPN\t\t29.98%\t\t18.79%\t\t51.06%\t\t0.17%\t\t5210\n",
      "JPN_MEX\t\t47.42%\t\t41.86%\t\t10.45%\t\t0.27%\t\t5167\n",
      "JPN_MYS\t\t26.24%\t\t21.50%\t\t51.70%\t\t0.56%\t\t5149\n",
      "JPN_PHL\t\t36.71%\t\t40.44%\t\t20.70%\t\t2.14%\t\t5222\n",
      "JPN_THA\t\t32.05%\t\t47.10%\t\t19.10%\t\t1.75%\t\t5214\n"
     ]
    }
   ],
   "source": [
    "print('FTA\\t\\tChapter\\t\\tHeading\\t\\tSubheading\\tOther\\t\\tTotal')\n",
    "for fta, rules in roo_rules.items():\n",
    "    total = len(rules)\n",
    "    try:\n",
    "        chapter = roo_types_count[fta]['chapter'] / total\n",
    "        heading = roo_types_count[fta]['heading'] / total\n",
    "        subheading = roo_types_count[fta]['subheading'] / total\n",
    "    except:\n",
    "        continue\n",
    "    other = 1 - (chapter + heading + subheading)\n",
    "    print('{}\\t\\t{:2.2%}\\t\\t{:2.2%}\\t\\t{:2.2%}\\t\\t{:2.2%}\\t\\t{}'.format(fta, chapter, heading, subheading, other, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTA\t\tChapter\t\tHeading\t\tSubheading\tOther\t\tTotal\n",
      "BRN_JPN\t\t38.89%\t\t15.56%\t\t36.39%\t\t9.17%\t\t360\n",
      "CHL_JPN\t\t28.06%\t\t45.20%\t\t22.30%\t\t4.43%\t\t677\n",
      "IDN_JPN\t\t51.22%\t\t21.14%\t\t27.37%\t\t0.27%\t\t369\n",
      "IND_JPN\t\t8.22%\t\t73.74%\t\t0.27%\t\t17.77%\t\t377\n",
      "JPN_MEX\t\t22.38%\t\t58.54%\t\t18.02%\t\t1.06%\t\t849\n",
      "JPN_MYS\t\t41.96%\t\t29.76%\t\t26.19%\t\t2.08%\t\t336\n",
      "JPN_PER\t\t32.88%\t\t40.36%\t\t19.27%\t\t7.48%\t\t441\n",
      "JPN_PHL\t\t29.09%\t\t37.48%\t\t27.13%\t\t6.29%\t\t715\n",
      "JPN_THA\t\t25.45%\t\t41.36%\t\t28.08%\t\t5.12%\t\t723\n"
     ]
    }
   ],
   "source": [
    "# OLD ONE\n",
    "print('FTA\\t\\tChapter\\t\\tHeading\\t\\tSubheading\\tOther\\t\\tTotal')\n",
    "for fta, rules in roo_rules.items():\n",
    "    total = len(rules)\n",
    "    chapter = roo_types_count[fta]['chapter'] / total\n",
    "    heading = roo_types_count[fta]['heading'] / total\n",
    "    subheading = roo_types_count[fta]['subheading'] / total\n",
    "    other = 1 - (chapter + heading + subheading)\n",
    "    print('{}\\t\\t{:2.2%}\\t\\t{:2.2%}\\t\\t{:2.2%}\\t\\t{:2.2%}\\t\\t{}'.format(fta, chapter, heading, subheading, other, total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
